{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\noklab\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sensor_0</th>\n",
       "      <th>sensor_1</th>\n",
       "      <th>sensor_2</th>\n",
       "      <th>sensor_3</th>\n",
       "      <th>sensor_4</th>\n",
       "      <th>sensor_5</th>\n",
       "      <th>sensor_6</th>\n",
       "      <th>sensor_7</th>\n",
       "      <th>sensor_8</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_13</th>\n",
       "      <th>sensor_14</th>\n",
       "      <th>sensor_15</th>\n",
       "      <th>sensor_16</th>\n",
       "      <th>sensor_17</th>\n",
       "      <th>sensor_18</th>\n",
       "      <th>sensor_19</th>\n",
       "      <th>parcel_0</th>\n",
       "      <th>parcel_1</th>\n",
       "      <th>parcel_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  sensor_0  sensor_1  sensor_2  sensor_3  sensor_4  sensor_5  \\\n",
       "0           0       1.0       2.0       1.0       7.0       0.0       1.0   \n",
       "1           1       5.0       1.0       3.0       5.0       2.0       2.0   \n",
       "2           2       3.0       1.0       4.0       3.0       4.0       0.0   \n",
       "3           3       2.0       2.0       4.0       3.0       5.0       0.0   \n",
       "4           4       4.0       3.0       3.0       2.0       5.0       1.0   \n",
       "\n",
       "   sensor_6  sensor_7  sensor_8  ...  sensor_13  sensor_14  sensor_15  \\\n",
       "0       1.0       4.0       0.0  ...        8.0        1.0        0.0   \n",
       "1       1.0       2.0       3.0  ...        4.0        5.0        5.0   \n",
       "2       1.0       6.0       0.0  ...        3.0        3.0        1.0   \n",
       "3       3.0       2.0       2.0  ...        4.0        1.0        1.0   \n",
       "4       3.0       1.0       1.0  ...        1.0        3.0        2.0   \n",
       "\n",
       "   sensor_16  sensor_17  sensor_18  sensor_19  parcel_0  parcel_1  parcel_2  \n",
       "0        2.0        1.0        9.0        2.0         0         1         0  \n",
       "1        2.0        2.0        2.0        7.0         0         0         0  \n",
       "2        0.0        3.0        1.0        0.0         1         1         0  \n",
       "3        4.0        1.0        3.0        2.0         0         0         0  \n",
       "4        2.0        1.0        1.0        0.0         1         1         0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irr_machine = pd.read_csv('irrigation_machine.csv')\n",
    "irr_machine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                1344      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 1,539\n",
      "Trainable params: 1,539\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Import the sequential model and dense layer\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Instantiate a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add a hidden layer of 64 neurons and a 20 neuron's input\n",
    "model.add(Dense(64, input_shape=(20,), activation='relu'))\n",
    "\n",
    "# Add an output layer of 3 neurons with sigmoid activation\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "# Compile your model with adam and binary crossentropy loss\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcels = irr_machine[['parcel_0','parcel_1','parcel_2']]\n",
    "sensors= irr_machine.drop(['parcel_0','parcel_1','parcel_2','Unnamed: 0'], axis=1)\n",
    "sensors_train,sensors_test,parcels_train,parcels_test = train_test_split(sensors, parcels, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1400 samples, validate on 600 samples\n",
      "Epoch 1/100\n",
      "1400/1400 [==============================] - 0s 102us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1156 - val_acc: 0.8850\n",
      "Epoch 2/100\n",
      "1400/1400 [==============================] - 0s 104us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1168 - val_acc: 0.8828\n",
      "Epoch 3/100\n",
      "1400/1400 [==============================] - 0s 105us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1165 - val_acc: 0.8833\n",
      "Epoch 4/100\n",
      "1400/1400 [==============================] - 0s 109us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1127 - val_acc: 0.8861\n",
      "Epoch 5/100\n",
      "1400/1400 [==============================] - 0s 100us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1146 - val_acc: 0.8861\n",
      "Epoch 6/100\n",
      "1400/1400 [==============================] - 0s 112us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1163 - val_acc: 0.8856\n",
      "Epoch 7/100\n",
      "1400/1400 [==============================] - 0s 106us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1162 - val_acc: 0.8839\n",
      "Epoch 8/100\n",
      "1400/1400 [==============================] - 0s 104us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1182 - val_acc: 0.8844\n",
      "Epoch 9/100\n",
      "1400/1400 [==============================] - 0s 108us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1166 - val_acc: 0.8833\n",
      "Epoch 10/100\n",
      "1400/1400 [==============================] - 0s 107us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1161 - val_acc: 0.8856\n",
      "Epoch 11/100\n",
      "1400/1400 [==============================] - 0s 105us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1197 - val_acc: 0.8839\n",
      "Epoch 12/100\n",
      "1400/1400 [==============================] - 0s 110us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1189 - val_acc: 0.8844\n",
      "Epoch 13/100\n",
      "1400/1400 [==============================] - 0s 104us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1173 - val_acc: 0.8850\n",
      "Epoch 14/100\n",
      "1400/1400 [==============================] - 0s 104us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1180 - val_acc: 0.8844\n",
      "Epoch 15/100\n",
      "1400/1400 [==============================] - 0s 105us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1217 - val_acc: 0.8844\n",
      "Epoch 16/100\n",
      "1400/1400 [==============================] - 0s 110us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1147 - val_acc: 0.8878\n",
      "Epoch 17/100\n",
      "1400/1400 [==============================] - 0s 128us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1211 - val_acc: 0.8833\n",
      "Epoch 18/100\n",
      "1400/1400 [==============================] - 0s 111us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1194 - val_acc: 0.8833\n",
      "Epoch 19/100\n",
      "1400/1400 [==============================] - 0s 104us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1191 - val_acc: 0.8839\n",
      "Epoch 20/100\n",
      "1400/1400 [==============================] - 0s 104us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1207 - val_acc: 0.8844\n",
      "Epoch 21/100\n",
      "1400/1400 [==============================] - 0s 104us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1220 - val_acc: 0.8844\n",
      "Epoch 22/100\n",
      "1400/1400 [==============================] - 0s 113us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1210 - val_acc: 0.8833\n",
      "Epoch 23/100\n",
      "1400/1400 [==============================] - 0s 106us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1166 - val_acc: 0.8856\n",
      "Epoch 24/100\n",
      "1400/1400 [==============================] - 0s 106us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1195 - val_acc: 0.8833\n",
      "Epoch 25/100\n",
      "1400/1400 [==============================] - 0s 106us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1212 - val_acc: 0.8844\n",
      "Epoch 26/100\n",
      "1400/1400 [==============================] - 0s 112us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1240 - val_acc: 0.8844\n",
      "Epoch 27/100\n",
      "1400/1400 [==============================] - 0s 132us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1200 - val_acc: 0.8844\n",
      "Epoch 28/100\n",
      "1400/1400 [==============================] - 0s 113us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1214 - val_acc: 0.8844\n",
      "Epoch 29/100\n",
      "1400/1400 [==============================] - 0s 102us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1197 - val_acc: 0.8844\n",
      "Epoch 30/100\n",
      "1400/1400 [==============================] - 0s 132us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1204 - val_acc: 0.8833\n",
      "Epoch 31/100\n",
      "1400/1400 [==============================] - 0s 121us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1202 - val_acc: 0.8850\n",
      "Epoch 32/100\n",
      "1400/1400 [==============================] - 0s 103us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1205 - val_acc: 0.8844\n",
      "Epoch 33/100\n",
      "1400/1400 [==============================] - 0s 138us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1265 - val_acc: 0.8828\n",
      "Epoch 34/100\n",
      "1400/1400 [==============================] - 0s 127us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1240 - val_acc: 0.8844\n",
      "Epoch 35/100\n",
      "1400/1400 [==============================] - 0s 105us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1208 - val_acc: 0.8833\n",
      "Epoch 36/100\n",
      "1400/1400 [==============================] - 0s 108us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1224 - val_acc: 0.8839\n",
      "Epoch 37/100\n",
      "1400/1400 [==============================] - 0s 97us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1234 - val_acc: 0.8844\n",
      "Epoch 38/100\n",
      "1400/1400 [==============================] - 0s 109us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1252 - val_acc: 0.8839\n",
      "Epoch 39/100\n",
      "1400/1400 [==============================] - 0s 126us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1264 - val_acc: 0.8833\n",
      "Epoch 40/100\n",
      "1400/1400 [==============================] - 0s 123us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1224 - val_acc: 0.8850\n",
      "Epoch 41/100\n",
      "1400/1400 [==============================] - 0s 112us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1235 - val_acc: 0.8861\n",
      "Epoch 42/100\n",
      "1400/1400 [==============================] - 0s 101us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1231 - val_acc: 0.8850\n",
      "Epoch 43/100\n",
      "1400/1400 [==============================] - 0s 102us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1259 - val_acc: 0.8833\n",
      "Epoch 44/100\n",
      "1400/1400 [==============================] - 0s 105us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1253 - val_acc: 0.8833\n",
      "Epoch 45/100\n",
      "1400/1400 [==============================] - 0s 111us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1256 - val_acc: 0.8822\n",
      "Epoch 46/100\n",
      "1400/1400 [==============================] - ETA: 0s - loss: 0.0199 - acc: 0.998 - 0s 100us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1266 - val_acc: 0.8844\n",
      "Epoch 47/100\n",
      "1400/1400 [==============================] - 0s 106us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1278 - val_acc: 0.8833\n",
      "Epoch 48/100\n",
      "1400/1400 [==============================] - 0s 104us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1279 - val_acc: 0.8844\n",
      "Epoch 49/100\n",
      "1400/1400 [==============================] - 0s 113us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1277 - val_acc: 0.8850\n",
      "Epoch 50/100\n",
      "1400/1400 [==============================] - 0s 113us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1261 - val_acc: 0.8833\n",
      "Epoch 51/100\n",
      "1400/1400 [==============================] - 0s 112us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1287 - val_acc: 0.8844\n",
      "Epoch 52/100\n",
      "1400/1400 [==============================] - 0s 105us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1271 - val_acc: 0.8839\n",
      "Epoch 53/100\n",
      "1400/1400 [==============================] - 0s 110us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1327 - val_acc: 0.8844\n",
      "Epoch 54/100\n",
      "1400/1400 [==============================] - 0s 104us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1272 - val_acc: 0.8850\n",
      "Epoch 55/100\n",
      "1400/1400 [==============================] - 0s 102us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1244 - val_acc: 0.8839\n",
      "Epoch 56/100\n",
      "1400/1400 [==============================] - 0s 110us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1321 - val_acc: 0.8844\n",
      "Epoch 57/100\n",
      "1400/1400 [==============================] - 0s 106us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1280 - val_acc: 0.8839\n",
      "Epoch 58/100\n",
      "1400/1400 [==============================] - 0s 115us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1283 - val_acc: 0.8822\n",
      "Epoch 59/100\n",
      "1400/1400 [==============================] - 0s 137us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1291 - val_acc: 0.8850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "1400/1400 [==============================] - 0s 110us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1305 - val_acc: 0.8822\n",
      "Epoch 61/100\n",
      "1400/1400 [==============================] - 0s 122us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1344 - val_acc: 0.8844\n",
      "Epoch 62/100\n",
      "1400/1400 [==============================] - 0s 124us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1337 - val_acc: 0.8833\n",
      "Epoch 63/100\n",
      "1400/1400 [==============================] - 0s 108us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1298 - val_acc: 0.8844\n",
      "Epoch 64/100\n",
      "1400/1400 [==============================] - 0s 99us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1555 - val_acc: 0.8806\n",
      "Epoch 65/100\n",
      "1400/1400 [==============================] - 0s 102us/step - loss: 0.0446 - acc: 0.9907 - val_loss: 1.1638 - val_acc: 0.8833\n",
      "Epoch 66/100\n",
      "1400/1400 [==============================] - 0s 98us/step - loss: 0.0438 - acc: 0.9910 - val_loss: 1.1770 - val_acc: 0.8817\n",
      "Epoch 67/100\n",
      "1400/1400 [==============================] - 0s 99us/step - loss: 0.0265 - acc: 0.9976 - val_loss: 1.1351 - val_acc: 0.8856\n",
      "Epoch 68/100\n",
      "1400/1400 [==============================] - 0s 100us/step - loss: 0.0234 - acc: 0.9986 - val_loss: 1.1465 - val_acc: 0.8850\n",
      "Epoch 69/100\n",
      "1400/1400 [==============================] - 0s 100us/step - loss: 0.0231 - acc: 0.9986 - val_loss: 1.1397 - val_acc: 0.8856\n",
      "Epoch 70/100\n",
      "1400/1400 [==============================] - 0s 102us/step - loss: 0.0230 - acc: 0.9986 - val_loss: 1.1401 - val_acc: 0.8867\n",
      "Epoch 71/100\n",
      "1400/1400 [==============================] - 0s 94us/step - loss: 0.0230 - acc: 0.9986 - val_loss: 1.1409 - val_acc: 0.8861\n",
      "Epoch 72/100\n",
      "1400/1400 [==============================] - 0s 129us/step - loss: 0.0230 - acc: 0.9986 - val_loss: 1.1409 - val_acc: 0.8867\n",
      "Epoch 73/100\n",
      "1400/1400 [==============================] - 0s 121us/step - loss: 0.0230 - acc: 0.9986 - val_loss: 1.1405 - val_acc: 0.8878\n",
      "Epoch 74/100\n",
      "1400/1400 [==============================] - 0s 98us/step - loss: 0.0230 - acc: 0.9986 - val_loss: 1.1402 - val_acc: 0.8878\n",
      "Epoch 75/100\n",
      "1400/1400 [==============================] - 0s 133us/step - loss: 0.0230 - acc: 0.9986 - val_loss: 1.1408 - val_acc: 0.8883\n",
      "Epoch 76/100\n",
      "1400/1400 [==============================] - 0s 143us/step - loss: 0.0230 - acc: 0.9986 - val_loss: 1.1410 - val_acc: 0.8883\n",
      "Epoch 77/100\n",
      "1400/1400 [==============================] - 0s 129us/step - loss: 0.0230 - acc: 0.9986 - val_loss: 1.1408 - val_acc: 0.8878\n",
      "Epoch 78/100\n",
      "1400/1400 [==============================] - 0s 113us/step - loss: 0.0230 - acc: 0.9986 - val_loss: 1.1409 - val_acc: 0.8878\n",
      "Epoch 79/100\n",
      "1400/1400 [==============================] - 0s 137us/step - loss: 0.0230 - acc: 0.9986 - val_loss: 1.1411 - val_acc: 0.8872\n",
      "Epoch 80/100\n",
      "1400/1400 [==============================] - 0s 105us/step - loss: 0.0230 - acc: 0.9986 - val_loss: 1.1415 - val_acc: 0.8867\n",
      "Epoch 81/100\n",
      "1400/1400 [==============================] - 0s 102us/step - loss: 0.0230 - acc: 0.9986 - val_loss: 1.1415 - val_acc: 0.8867\n",
      "Epoch 82/100\n",
      "1400/1400 [==============================] - 0s 170us/step - loss: 0.0230 - acc: 0.9986 - val_loss: 1.1415 - val_acc: 0.8861\n",
      "Epoch 83/100\n",
      "1400/1400 [==============================] - 0s 106us/step - loss: 0.0230 - acc: 0.9986 - val_loss: 1.1422 - val_acc: 0.8861\n",
      "Epoch 84/100\n",
      "1400/1400 [==============================] - 0s 105us/step - loss: 0.0230 - acc: 0.9986 - val_loss: 1.1410 - val_acc: 0.8856\n",
      "Epoch 85/100\n",
      "1400/1400 [==============================] - 0s 100us/step - loss: 0.0230 - acc: 0.9986 - val_loss: 1.1421 - val_acc: 0.8861\n",
      "Epoch 86/100\n",
      "1400/1400 [==============================] - 0s 90us/step - loss: 0.0230 - acc: 0.9986 - val_loss: 1.1416 - val_acc: 0.8856\n",
      "Epoch 87/100\n",
      "1400/1400 [==============================] - 0s 108us/step - loss: 0.0230 - acc: 0.9986 - val_loss: 1.1419 - val_acc: 0.8856\n",
      "Epoch 88/100\n",
      "1400/1400 [==============================] - 0s 110us/step - loss: 0.0230 - acc: 0.9986 - val_loss: 1.1418 - val_acc: 0.8856\n",
      "Epoch 89/100\n",
      "1400/1400 [==============================] - 0s 102us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1421 - val_acc: 0.8856\n",
      "Epoch 90/100\n",
      "1400/1400 [==============================] - 0s 89us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1429 - val_acc: 0.8844\n",
      "Epoch 91/100\n",
      "1400/1400 [==============================] - 0s 106us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1421 - val_acc: 0.8856\n",
      "Epoch 92/100\n",
      "1400/1400 [==============================] - 0s 102us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1429 - val_acc: 0.8850\n",
      "Epoch 93/100\n",
      "1400/1400 [==============================] - 0s 106us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1430 - val_acc: 0.8844\n",
      "Epoch 94/100\n",
      "1400/1400 [==============================] - 0s 105us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1429 - val_acc: 0.8844\n",
      "Epoch 95/100\n",
      "1400/1400 [==============================] - 0s 110us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1430 - val_acc: 0.8844\n",
      "Epoch 96/100\n",
      "1400/1400 [==============================] - 0s 101us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1428 - val_acc: 0.8839\n",
      "Epoch 97/100\n",
      "1400/1400 [==============================] - 0s 104us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1437 - val_acc: 0.8839\n",
      "Epoch 98/100\n",
      "1400/1400 [==============================] - 0s 103us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1430 - val_acc: 0.8844\n",
      "Epoch 99/100\n",
      "1400/1400 [==============================] - 0s 105us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1433 - val_acc: 0.8844\n",
      "Epoch 100/100\n",
      "1400/1400 [==============================] - 0s 98us/step - loss: 0.0229 - acc: 0.9986 - val_loss: 1.1436 - val_acc: 0.8844\n",
      "Rounded Predictions: \n",
      " [[0. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [1. 1. 0.]\n",
      " ...\n",
      " [1. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 1. 1.]]\n",
      "600/600 [==============================] - 0s 55us/step\n",
      "Accuracy: 0.8844444592793782\n"
     ]
    }
   ],
   "source": [
    "# Train for 100 epochs using a validation split of 0.5\n",
    "history = model.fit(sensors_train, parcels_train, epochs=100, validation_data=(sensors_test, parcels_test), validation_split=0.5)\n",
    "\n",
    "# Predict on sensors_test and round up the predictions\n",
    "preds = model.predict(sensors_test)\n",
    "preds_rounded = np.round(preds)\n",
    "\n",
    "# Print rounded preds\n",
    "print('Rounded Predictions: \\n', preds_rounded)\n",
    "\n",
    "# Evaluate your model's accuracy on the test data\n",
    "accuracy = model.evaluate(sensors_test, parcels_test)[1]\n",
    "\n",
    "# Print accuracy\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot train vs test loss during training\n",
    "plt.plot(history.history['loss'], history.history['val_loss'])\n",
    "\n",
    "# Plot train vs test accuracy during training\n",
    "plt.plot(history.history['acc'], history.history['val_acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
