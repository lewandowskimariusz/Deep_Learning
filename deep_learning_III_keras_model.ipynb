{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.keras.metrics import Metric\n",
    "import keras.backend\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>male</th>\n",
       "      <th>embarked_from_cherbourg</th>\n",
       "      <th>embarked_from_queenstown</th>\n",
       "      <th>embarked_from_southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>0.647587</td>\n",
       "      <td>0.188552</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>0.722783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>13.002015</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>0.477990</td>\n",
       "      <td>0.391372</td>\n",
       "      <td>0.281141</td>\n",
       "      <td>0.447876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         survived      pclass         age       sibsp       parch        fare  \\\n",
       "count  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000   \n",
       "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208   \n",
       "std      0.486592    0.836071   13.002015    1.102743    0.806057   49.693429   \n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    2.000000   22.000000    0.000000    0.000000    7.910400   \n",
       "50%      0.000000    3.000000   29.699118    0.000000    0.000000   14.454200   \n",
       "75%      1.000000    3.000000   35.000000    1.000000    0.000000   31.000000   \n",
       "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200   \n",
       "\n",
       "             male  embarked_from_cherbourg  embarked_from_queenstown  \\\n",
       "count  891.000000               891.000000                891.000000   \n",
       "mean     0.647587                 0.188552                  0.086420   \n",
       "std      0.477990                 0.391372                  0.281141   \n",
       "min      0.000000                 0.000000                  0.000000   \n",
       "25%      0.000000                 0.000000                  0.000000   \n",
       "50%      1.000000                 0.000000                  0.000000   \n",
       "75%      1.000000                 0.000000                  0.000000   \n",
       "max      1.000000                 1.000000                  1.000000   \n",
       "\n",
       "       embarked_from_southampton  \n",
       "count                 891.000000  \n",
       "mean                    0.722783  \n",
       "std                     0.447876  \n",
       "min                     0.000000  \n",
       "25%                     0.000000  \n",
       "50%                     1.000000  \n",
       "75%                     1.000000  \n",
       "max                     1.000000  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('titanic_all_numeric.csv')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = df.iloc[:,1:].values\n",
    "n_cols = predictors.shape[1]\n",
    "\n",
    "# Convert the target to categorical: target\n",
    "target = to_categorical(df.survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(predictors, target, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing model with learning rate: 0.001000\n",
      "\n",
      "Train on 436 samples, validate on 187 samples\n",
      "Epoch 1/100\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 1.1445 - acc: 0.5413 - val_loss: 0.7165 - val_acc: 0.6471\n",
      "Epoch 2/100\n",
      "436/436 [==============================] - 0s 96us/step - loss: 0.6766 - acc: 0.6651 - val_loss: 0.6746 - val_acc: 0.6524\n",
      "Epoch 3/100\n",
      "436/436 [==============================] - 0s 94us/step - loss: 0.6506 - acc: 0.6720 - val_loss: 0.7500 - val_acc: 0.5882\n",
      "Epoch 4/100\n",
      "436/436 [==============================] - 0s 101us/step - loss: 0.6479 - acc: 0.6560 - val_loss: 0.6393 - val_acc: 0.6791\n",
      "Epoch 5/100\n",
      "436/436 [==============================] - 0s 110us/step - loss: 0.6474 - acc: 0.6514 - val_loss: 0.6388 - val_acc: 0.6578\n",
      "Epoch 6/100\n",
      "436/436 [==============================] - 0s 110us/step - loss: 0.6505 - acc: 0.6583 - val_loss: 0.6910 - val_acc: 0.5775\n",
      "Epoch 7/100\n",
      "436/436 [==============================] - 0s 110us/step - loss: 0.6261 - acc: 0.6674 - val_loss: 0.6504 - val_acc: 0.6524\n",
      "Epoch 8/100\n",
      "436/436 [==============================] - 0s 95us/step - loss: 0.6277 - acc: 0.6697 - val_loss: 0.6300 - val_acc: 0.6578\n",
      "Epoch 9/100\n",
      "436/436 [==============================] - 0s 94us/step - loss: 0.6687 - acc: 0.6606 - val_loss: 0.6298 - val_acc: 0.6578\n",
      "Epoch 10/100\n",
      "436/436 [==============================] - 0s 110us/step - loss: 0.6208 - acc: 0.6720 - val_loss: 0.6498 - val_acc: 0.6203\n",
      "Epoch 11/100\n",
      "436/436 [==============================] - 0s 101us/step - loss: 0.6301 - acc: 0.6651 - val_loss: 0.6266 - val_acc: 0.6684\n",
      "Epoch 12/100\n",
      "436/436 [==============================] - 0s 98us/step - loss: 0.6492 - acc: 0.6606 - val_loss: 0.6303 - val_acc: 0.6898\n",
      "Epoch 13/100\n",
      "436/436 [==============================] - 0s 100us/step - loss: 0.6232 - acc: 0.6789 - val_loss: 0.6335 - val_acc: 0.6631\n",
      "Epoch 14/100\n",
      "436/436 [==============================] - 0s 142us/step - loss: 0.6241 - acc: 0.6881 - val_loss: 0.6418 - val_acc: 0.6631\n",
      "Epoch 15/100\n",
      "436/436 [==============================] - 0s 130us/step - loss: 0.6502 - acc: 0.6628 - val_loss: 0.6859 - val_acc: 0.5882\n",
      "Epoch 16/100\n",
      "436/436 [==============================] - 0s 114us/step - loss: 0.6284 - acc: 0.6651 - val_loss: 0.6233 - val_acc: 0.6631\n",
      "Epoch 17/100\n",
      "436/436 [==============================] - 0s 130us/step - loss: 0.6245 - acc: 0.6697 - val_loss: 0.6247 - val_acc: 0.6684\n",
      "Epoch 18/100\n",
      "436/436 [==============================] - 0s 111us/step - loss: 0.6259 - acc: 0.6628 - val_loss: 0.7082 - val_acc: 0.6043\n",
      "Epoch 19/100\n",
      "436/436 [==============================] - 0s 98us/step - loss: 0.6323 - acc: 0.6468 - val_loss: 0.6664 - val_acc: 0.5829\n",
      "Epoch 20/100\n",
      "436/436 [==============================] - 0s 89us/step - loss: 0.6200 - acc: 0.6674 - val_loss: 0.6206 - val_acc: 0.6631\n",
      "Epoch 21/100\n",
      "436/436 [==============================] - 0s 96us/step - loss: 0.6179 - acc: 0.6720 - val_loss: 0.6356 - val_acc: 0.6738\n",
      "Epoch 22/100\n",
      "436/436 [==============================] - 0s 98us/step - loss: 0.6242 - acc: 0.6835 - val_loss: 0.8776 - val_acc: 0.5829\n",
      "Epoch 23/100\n",
      "436/436 [==============================] - 0s 104us/step - loss: 0.6315 - acc: 0.6628 - val_loss: 0.6195 - val_acc: 0.6684\n",
      "Epoch 24/100\n",
      "436/436 [==============================] - 0s 101us/step - loss: 0.6133 - acc: 0.6858 - val_loss: 0.6220 - val_acc: 0.6684\n",
      "Epoch 25/100\n",
      "436/436 [==============================] - 0s 105us/step - loss: 0.6171 - acc: 0.6468 - val_loss: 0.6694 - val_acc: 0.6096\n",
      "Epoch 26/100\n",
      "436/436 [==============================] - 0s 113us/step - loss: 0.6141 - acc: 0.6606 - val_loss: 0.6220 - val_acc: 0.6631\n",
      "Epoch 27/100\n",
      "436/436 [==============================] - 0s 110us/step - loss: 0.6275 - acc: 0.6697 - val_loss: 0.6260 - val_acc: 0.6898\n",
      "Epoch 28/100\n",
      "436/436 [==============================] - 0s 105us/step - loss: 0.6086 - acc: 0.6835 - val_loss: 0.6753 - val_acc: 0.6043\n",
      "\n",
      "\n",
      "Testing model with learning rate: 0.050000\n",
      "\n",
      "Train on 436 samples, validate on 187 samples\n",
      "Epoch 1/100\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 7.2520 - acc: 0.4725 - val_loss: 9.3950 - val_acc: 0.4171\n",
      "Epoch 2/100\n",
      "436/436 [==============================] - 0s 98us/step - loss: 10.2032 - acc: 0.3670 - val_loss: 9.3950 - val_acc: 0.4171\n",
      "Epoch 3/100\n",
      "436/436 [==============================] - 0s 114us/step - loss: 10.2032 - acc: 0.3670 - val_loss: 9.3950 - val_acc: 0.4171\n",
      "Epoch 4/100\n",
      "436/436 [==============================] - 0s 167us/step - loss: 10.2032 - acc: 0.3670 - val_loss: 9.3950 - val_acc: 0.4171\n",
      "Epoch 5/100\n",
      "436/436 [==============================] - 0s 121us/step - loss: 10.2032 - acc: 0.3670 - val_loss: 9.3950 - val_acc: 0.4171\n",
      "Epoch 6/100\n",
      "436/436 [==============================] - 0s 151us/step - loss: 10.2032 - acc: 0.3670 - val_loss: 9.3950 - val_acc: 0.4171\n",
      "\n",
      "\n",
      "Testing model with learning rate: 1.000000\n",
      "\n",
      "Train on 436 samples, validate on 187 samples\n",
      "Epoch 1/100\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 5.5147 - acc: 0.6376 - val_loss: 6.7231 - val_acc: 0.5829\n",
      "Epoch 2/100\n",
      "436/436 [==============================] - 0s 113us/step - loss: 5.9149 - acc: 0.6330 - val_loss: 6.7231 - val_acc: 0.5829\n",
      "Epoch 3/100\n",
      "436/436 [==============================] - 0s 124us/step - loss: 5.9149 - acc: 0.6330 - val_loss: 6.7231 - val_acc: 0.5829\n",
      "Epoch 4/100\n",
      "436/436 [==============================] - 0s 115us/step - loss: 5.9149 - acc: 0.6330 - val_loss: 6.7231 - val_acc: 0.5829\n",
      "Epoch 5/100\n",
      "436/436 [==============================] - 0s 114us/step - loss: 5.9149 - acc: 0.6330 - val_loss: 6.7231 - val_acc: 0.5829\n",
      "Epoch 6/100\n",
      "436/436 [==============================] - 0s 101us/step - loss: 5.9149 - acc: 0.6330 - val_loss: 6.7231 - val_acc: 0.5829\n"
     ]
    }
   ],
   "source": [
    "# Define early_stopping_monitor\n",
    "early_stopping_monitor = EarlyStopping(patience=5)\n",
    "# Set up the model\n",
    "def get_new_model(n_cols):\n",
    "    #Create model\n",
    "    model = Sequential()\n",
    "    # Add the first layer\n",
    "    model.add(Dense(128, activation='relu', input_shape=(n_cols,)))\n",
    "    # Add the second layer\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    # Add the third layer\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    # Add the output layer\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "# Learning rates\n",
    "lr_to_test = [0.001,0.05,1]\n",
    "# Loop over learning rates\n",
    "for lr in lr_to_test:\n",
    "    print('\\n\\nTesting model with learning rate: %f\\n'%lr )\n",
    "    model = get_new_model(n_cols)\n",
    "    my_optimizer = SGD(lr=lr)\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=my_optimizer, \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train,validation_split=0.3,epochs=100,callbacks=[early_stopping_monitor],verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
